{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "def create_spark_session():\n",
    "    return (SparkSession.builder\n",
    "            .appName(\"FlightDataProcessor\")\n",
    "            .config(\"spark.jars.packages\", \"org.apache.spark:spark-sql-kafka-0-10_2.12:3.2.0\")\n",
    "            .config(\"spark.sql.shuffle.partitions\", \"2\")\n",
    "            .getOrCreate())\n",
    "\n",
    "def process_stream(df, epoch_id):\n",
    "    \"\"\"\n",
    "    Xử lý mỗi batch của streaming data\n",
    "    \"\"\"\n",
    "    # Định nghĩa schema cho dữ liệu flight\n",
    "    schema = StructType([\n",
    "        StructField(\"date\", StringType()),\n",
    "        StructField(\"Scheduled_Time\", StringType()),\n",
    "        StructField(\"Updated_Time\", StringType()),\n",
    "        StructField(\"Route\", StringType()),\n",
    "        StructField(\"Flight\", StringType()),\n",
    "        StructField(\"Counter\", StringType()),\n",
    "        StructField(\"Gate\", StringType()),\n",
    "        StructField(\"Status\", StringType())\n",
    "    ])\n",
    "    \n",
    "    # Parse JSON và xử lý dữ liệu\n",
    "    parsed_df = df.selectExpr(\"CAST(value AS STRING)\") \\\n",
    "        .select(from_json(col(\"value\"), schema).alias(\"data\")) \\\n",
    "        .select(\"data.*\")\n",
    "    \n",
    "    # Thêm các cột phân tích\n",
    "    processed_df = parsed_df \\\n",
    "        .withColumn(\"processing_timestamp\", current_timestamp()) \\\n",
    "        .withColumn(\"departure_airport\", split(col(\"Route\"), \"-\")[0]) \\\n",
    "        .withColumn(\"arrival_airport\", split(col(\"Route\"), \"-\")[1]) \\\n",
    "        .withColumn(\"is_delayed\", \n",
    "                   when(col(\"Updated_Time\") != col(\"Scheduled_Time\"), \"Yes\")\n",
    "                   .otherwise(\"No\"))\n",
    "    \n",
    "    # Ghi vào MySQL\n",
    "    processed_df.write \\\n",
    "        .format(\"jdbc\") \\\n",
    "        .mode(\"append\") \\\n",
    "        .option(\"driver\", \"com.mysql.cj.jdbc.Driver\") \\\n",
    "        .option(\"url\", \"jdbc:mysql://localhost:3306/mydatabase\") \\\n",
    "        .option(\"dbtable\", \"flight_info\") \\\n",
    "        .option(\"user\", \"user\") \\\n",
    "        .option(\"password\", \"password\") \\\n",
    "        .save()\n",
    "    \n",
    "    # Hiển thị kết quả\n",
    "    processed_df.show(truncate=False)\n",
    "\n",
    "def main():\n",
    "    # Tạo Spark Session\n",
    "    spark = create_spark_session()\n",
    "    \n",
    "    # Đọc từ Kafka\n",
    "    kafka_df = (spark\n",
    "                .readStream\n",
    "                .format(\"kafka\")\n",
    "                .option(\"kafka.bootstrap.servers\", \"localhost:9092\")\n",
    "                .option(\"subscribe\", \"flights\")  # Topic name từ producer\n",
    "                .option(\"startingOffsets\", \"latest\")\n",
    "                .load())\n",
    "    \n",
    "    # Xử lý stream\n",
    "    query = kafka_df.writeStream \\\n",
    "        .foreachBatch(process_stream) \\\n",
    "        .outputMode(\"update\") \\\n",
    "        .trigger(processingTime=\"5 seconds\") \\\n",
    "        .start()\n",
    "    \n",
    "    # Đợi đến khi streaming job kết thúc\n",
    "    query.awaitTermination()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
